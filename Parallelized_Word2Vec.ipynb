{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Element Logiciel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Après\n",
       "1     avoir\n",
       "2    débuté\n",
       "3      sous\n",
       "4        le\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On travaille sur un petit texte pour commencer\n",
    "text  = open(\"data/TheBeatles.txt\", \"r\") \n",
    "text = text.readlines()[0]\n",
    "\n",
    "#Preprocessing : on supprime la ponctuation\n",
    "not_alphabet=\"'?./§,;:!»«()…-\" \n",
    "for i in not_alphabet:\n",
    "    text = text.replace(i, \"\")\n",
    "text = text.split(\" \")\n",
    "text_serie = pd.Series(text)\n",
    "text_serie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "text_lb = LabelBinarizer()\n",
    "X_hot = text_lb.fit_transform(text_serie.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 645)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_hot)\n",
    "#Les lignes sont chaque mot du texte dans l'ordre\n",
    "#Les colonnes sont les différents mots\n",
    "#ici 1300 mots dont 645 différents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.apply_along_axis(np.argmax, 1, X_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40, 171, 263, ..., 596,   0,   0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "#Pour l'application on préfère définir chaque mot par un entier (ce qui est identique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogwild implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#à modifier\n",
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def hog_loop(Min,Mout,alpha,wout,Nwin,negative):\n",
    "    #Min matrice dans V*d\n",
    "    #Mout matrice dans V*d\n",
    "    #wout vecteur dans V*1 ou entier ? dans 0:V-1\n",
    "    #nwin n vecteurs de V*1 (ie matrice de V*n) ou n entiers de 0:V-1\n",
    "    V,d=Min.shape\n",
    "    N=Nwin.shape[0]\n",
    "    for i in range(N):\n",
    "        input_word = Nwin[i]\n",
    "        temp = np.array([0]*d)\n",
    "        for k in range(negative+1):\n",
    "            if k == 0:\n",
    "                target_word = wout\n",
    "                label = 1\n",
    "            else : \n",
    "                target_word = rd.randint(0,V-1)\n",
    "                label = 0\n",
    "            inn = np.dot(Min[input_word,:],Mout[target_word,:])\n",
    "            err = label - sig(inn)\n",
    "            temp = err*Mout[target_word,:]\n",
    "            Mout[target_word,:] = alpha*err*Min[input_word,:]\n",
    "        Min[input_word,:]=alpha*temp\n",
    "    return(Min,Mout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4.00752073e-01,  7.63665079e-01,  2.83175495e-01,\n",
       "          9.73136562e-01,  6.30078997e-01],\n",
       "        [-3.70131966e-04, -2.59880604e-04, -5.76724647e-04,\n",
       "         -4.18558105e-04, -5.69911934e-04],\n",
       "        [ 5.71208327e-02,  8.15611851e-01,  3.48116090e-01,\n",
       "          8.10722638e-01,  5.40749892e-01],\n",
       "        [ 2.85155766e-01,  4.80988030e-02,  8.11102102e-01,\n",
       "          9.95621141e-01,  4.24618848e-01],\n",
       "        [-6.97433563e-04, -2.66306038e-04, -4.23845588e-04,\n",
       "         -6.16004554e-04, -2.84309249e-04],\n",
       "        [ 1.09196782e-01,  3.10237482e-01,  3.51463760e-01,\n",
       "          4.82759970e-01,  9.91063713e-01],\n",
       "        [ 5.31372755e-01,  7.10029642e-01,  8.77509638e-01,\n",
       "          3.58524429e-01,  8.50577396e-01],\n",
       "        [ 5.99278752e-01,  4.45221083e-01,  2.04076040e-01,\n",
       "          7.38448999e-02,  2.53883885e-01],\n",
       "        [-1.00207369e-06, -4.91728831e-04, -6.32769603e-04,\n",
       "         -1.22754214e-04, -4.39896393e-04],\n",
       "        [ 4.31174790e-01,  8.79531661e-01,  3.37949221e-01,\n",
       "          2.95625008e-01,  7.16510395e-01],\n",
       "        [ 4.24754139e-01,  9.47868909e-01,  2.77098356e-02,\n",
       "          8.53402675e-01,  7.26842792e-01],\n",
       "        [ 5.81853686e-01,  1.58084457e-01,  1.82926491e-01,\n",
       "          6.80979644e-01,  4.45992572e-01],\n",
       "        [ 6.40978936e-01,  6.84637529e-01,  6.32569593e-02,\n",
       "          6.71292107e-03,  8.44393514e-01],\n",
       "        [ 5.81422935e-02,  9.85828520e-01,  2.96280355e-01,\n",
       "          8.70381723e-01,  2.87322355e-02],\n",
       "        [ 7.61467717e-01,  7.63552348e-01,  4.28816110e-01,\n",
       "          7.33607130e-01,  7.10722890e-01],\n",
       "        [ 1.32160727e-01,  3.59498133e-01,  2.34792777e-01,\n",
       "          1.95419723e-01,  7.44506742e-01],\n",
       "        [ 8.80860958e-01,  6.30298455e-01,  5.61670894e-01,\n",
       "          8.49524705e-01,  8.40328032e-01],\n",
       "        [ 2.35805644e-01,  6.28435264e-01,  5.15608591e-01,\n",
       "          7.75402624e-01,  2.89837417e-01],\n",
       "        [ 6.89985351e-01,  5.04052558e-01,  9.58618718e-01,\n",
       "          6.52502619e-01,  2.35190900e-01],\n",
       "        [ 4.49576876e-01,  4.21799262e-01,  2.47242358e-01,\n",
       "          9.00924544e-01,  5.04742767e-01],\n",
       "        [ 9.42990128e-01,  9.73088437e-01,  5.19368694e-01,\n",
       "          4.64092017e-01,  9.22732139e-01],\n",
       "        [ 7.40787692e-01,  6.99477553e-01,  8.05344256e-01,\n",
       "          7.35239285e-01,  8.96446143e-01],\n",
       "        [ 6.23109613e-02,  2.63160417e-01,  5.87675861e-01,\n",
       "          2.27443358e-01,  9.57735689e-01],\n",
       "        [ 6.05724525e-01,  9.96540781e-01,  3.28687449e-01,\n",
       "          4.80894295e-01,  5.31929865e-01],\n",
       "        [ 4.13698916e-01,  1.44212242e-01,  3.43688314e-01,\n",
       "          5.83571258e-01,  6.75169847e-01],\n",
       "        [ 4.76584835e-01,  8.94531785e-01,  2.95118108e-01,\n",
       "          9.53214055e-01,  6.99064576e-01],\n",
       "        [ 5.15000611e-01,  4.44049638e-01,  2.06034908e-01,\n",
       "          6.32113177e-01,  5.33363371e-01],\n",
       "        [-2.05639999e-05, -2.82770095e-04, -6.90225328e-04,\n",
       "         -7.42522590e-04, -1.99880799e-05],\n",
       "        [ 9.46386487e-02,  9.26893788e-01,  6.83437372e-01,\n",
       "          7.05625857e-01,  5.28379674e-01],\n",
       "        [ 3.24563817e-01,  7.74935550e-02,  1.15189061e-01,\n",
       "          8.49584368e-01,  6.24562642e-01],\n",
       "        [ 6.38723800e-02,  6.13770229e-02,  4.41872810e-01,\n",
       "          9.70045969e-01,  8.29267707e-01],\n",
       "        [ 2.62370077e-01,  4.74481803e-01,  5.73541601e-01,\n",
       "          8.86762381e-01,  1.33691247e-02],\n",
       "        [ 6.58047734e-02,  6.86792165e-01,  8.31002979e-01,\n",
       "          3.71066811e-01,  8.04798089e-01],\n",
       "        [ 2.52597156e-01,  3.51779541e-01,  3.01824950e-01,\n",
       "          2.86749486e-01,  7.53515965e-02],\n",
       "        [ 8.39682003e-01,  6.29685248e-01,  1.26060787e-01,\n",
       "          1.36330488e-01,  6.73548126e-01],\n",
       "        [ 4.16299361e-01,  2.89095054e-01,  4.69775156e-01,\n",
       "          1.45709724e-02,  5.41865809e-01],\n",
       "        [ 2.28322018e-01,  8.62638850e-01,  5.47105475e-01,\n",
       "          9.60423777e-01,  8.88969603e-01],\n",
       "        [ 6.05638577e-01,  1.77026387e-01,  2.68399038e-01,\n",
       "          7.61619174e-01,  2.93290837e-01],\n",
       "        [ 8.75814150e-01,  9.33336719e-01,  5.96494932e-01,\n",
       "          5.58576796e-01,  8.18532494e-01],\n",
       "        [ 2.69160035e-01,  8.75611794e-01,  6.16430464e-01,\n",
       "          4.41945773e-01,  9.74224170e-01],\n",
       "        [ 7.91730343e-01,  7.77584397e-01,  7.42634733e-01,\n",
       "          1.09051664e-01,  4.49117267e-01],\n",
       "        [ 2.53927369e-01,  8.68389989e-01,  8.23953689e-01,\n",
       "          6.79870175e-01,  5.71340380e-01],\n",
       "        [ 3.63153934e-01,  6.10884989e-01,  6.35582271e-01,\n",
       "          3.05078285e-01,  3.34438863e-01],\n",
       "        [ 2.54596617e-01,  7.08172423e-01,  6.71200848e-01,\n",
       "          1.67649126e-01,  1.70560526e-01],\n",
       "        [ 6.84022161e-01,  7.47708576e-02,  1.80208312e-01,\n",
       "          9.80478971e-01,  9.39370317e-01],\n",
       "        [ 6.86520033e-01,  4.87809630e-01,  7.32532572e-01,\n",
       "          2.24130411e-01,  6.54230144e-01],\n",
       "        [ 2.09620996e-01,  8.83824518e-01,  1.38819657e-01,\n",
       "          4.63801491e-01,  2.99887389e-02],\n",
       "        [ 6.44459139e-01,  4.21270124e-01,  1.40495158e-01,\n",
       "          6.81225086e-01,  6.04824742e-01],\n",
       "        [ 1.76901919e-01,  3.19904968e-01,  4.14590254e-01,\n",
       "          4.12351140e-01,  8.07885180e-01],\n",
       "        [ 8.04486961e-01,  9.73386418e-02,  7.69125586e-01,\n",
       "          2.69105592e-01,  3.16560072e-01]]),\n",
       " array([[-7.20678855e-05, -2.03950028e-04, -4.25490618e-04,\n",
       "         -1.17115667e-04, -2.07053212e-04],\n",
       "        [-1.76167023e-05, -1.01788167e-05, -2.05440364e-04,\n",
       "         -6.24189452e-04, -3.27197387e-04],\n",
       "        [ 4.04631805e-01,  6.17542408e-01,  2.41921481e-02,\n",
       "          5.11627752e-01,  2.19136121e-01],\n",
       "        [ 8.99738434e-01,  3.62617964e-01,  5.73757035e-01,\n",
       "          5.49492684e-01,  8.32369036e-01],\n",
       "        [ 6.12685370e-01,  6.27839639e-01,  1.31961071e-01,\n",
       "          8.62378793e-01,  5.61941270e-01],\n",
       "        [ 5.92167830e-01,  6.27150048e-01,  3.78722672e-02,\n",
       "          3.33427976e-02,  9.80795940e-01],\n",
       "        [ 2.78189019e-01,  2.98268542e-01,  7.32173677e-01,\n",
       "          8.64849293e-01,  6.43004860e-01],\n",
       "        [ 2.69867596e-01,  9.72091748e-01,  1.57226628e-01,\n",
       "          5.19534198e-01,  8.54431691e-01],\n",
       "        [-1.74754468e-05, -1.00972002e-05, -2.03793088e-04,\n",
       "         -6.19184533e-04, -3.24573830e-04],\n",
       "        [ 6.65160091e-01,  9.69712316e-02,  7.14305616e-01,\n",
       "          3.79766584e-01,  6.16305954e-01],\n",
       "        [ 1.27919893e-01,  1.44692012e-01,  7.08273090e-01,\n",
       "          9.70205497e-01,  1.06783139e-01],\n",
       "        [-7.39435435e-05, -2.09258086e-04, -4.36564550e-04,\n",
       "         -1.20163750e-04, -2.12442035e-04],\n",
       "        [ 5.14458405e-05,  1.45590238e-04,  3.03737543e-04,\n",
       "          8.36033119e-05,  1.47805454e-04],\n",
       "        [ 4.71070761e-01,  1.28655209e-01,  9.92389069e-01,\n",
       "          2.57404503e-02,  2.93329749e-01],\n",
       "        [ 5.73924890e-01,  9.06349546e-01,  3.68256072e-01,\n",
       "          9.77429982e-01,  5.53487886e-01],\n",
       "        [ 4.18101650e-02,  1.88189906e-01,  1.80669275e-01,\n",
       "          6.18968322e-01,  8.10650779e-01],\n",
       "        [-5.18052336e-04, -9.54840937e-05, -5.78742090e-05,\n",
       "         -3.06076635e-04, -5.92371308e-05],\n",
       "        [ 1.23815000e-01,  1.32988240e-01,  9.42303800e-01,\n",
       "          7.86627892e-01,  5.93967323e-01],\n",
       "        [ 1.31400999e-01,  5.90284185e-01,  9.11072056e-02,\n",
       "          6.68260757e-01,  4.17944412e-01],\n",
       "        [-5.96796026e-04, -4.44871095e-04, -7.04743788e-04,\n",
       "         -4.69325494e-04, -6.41227315e-04],\n",
       "        [ 1.60676485e-01,  1.04259868e-01,  5.28013474e-01,\n",
       "          3.29173114e-01,  5.43269247e-01],\n",
       "        [ 1.42067663e-01,  1.15564929e-01,  3.13633960e-01,\n",
       "          8.68168033e-01,  2.14974785e-01],\n",
       "        [ 2.82454476e-01,  1.50659473e-01,  6.90817359e-01,\n",
       "          8.75821888e-01,  5.11912622e-01],\n",
       "        [-4.24617683e-04, -7.82628160e-05, -4.74361581e-05,\n",
       "         -2.50873402e-04, -4.85532667e-05],\n",
       "        [ 4.16715245e-01,  9.22695982e-01,  8.64061730e-02,\n",
       "          7.25269937e-01,  8.17584375e-01],\n",
       "        [ 1.82683242e-01,  9.58587352e-01,  1.00403781e-01,\n",
       "          6.98124629e-01,  6.10813196e-01],\n",
       "        [-7.25443787e-04, -5.40769304e-04, -8.56661204e-04,\n",
       "         -5.70495193e-04, -7.79452863e-04],\n",
       "        [ 8.39352809e-01,  4.05058145e-01,  3.23165644e-01,\n",
       "          3.90913622e-02,  1.92587911e-02],\n",
       "        [ 6.80857549e-01,  6.95538846e-01,  8.81203988e-01,\n",
       "          6.48555918e-01,  6.86543012e-01],\n",
       "        [ 1.44280691e-01,  2.63870928e-01,  5.18446068e-01,\n",
       "          6.26603204e-01,  4.19532715e-01],\n",
       "        [-1.86777291e-05, -1.07918712e-05, -2.17813721e-04,\n",
       "         -6.61783421e-04, -3.46903981e-04],\n",
       "        [ 2.24221030e-01,  8.58865127e-01,  8.61109352e-02,\n",
       "          3.75762886e-01,  8.78540483e-02],\n",
       "        [ 8.93920262e-01,  5.98251956e-01,  8.25708828e-01,\n",
       "          6.01552768e-02,  3.81602937e-01],\n",
       "        [ 6.97409262e-01,  5.87745481e-01,  1.45543241e-01,\n",
       "          5.44345033e-01,  9.15602086e-01],\n",
       "        [ 3.07941970e-01,  7.76812666e-01,  7.35118021e-01,\n",
       "          6.27845539e-01,  4.59895379e-01],\n",
       "        [ 7.25210726e-01,  1.00662849e-01,  4.90264368e-01,\n",
       "          5.04020965e-01,  3.17766579e-01],\n",
       "        [-6.75304036e-04, -5.03393510e-04, -7.97452234e-04,\n",
       "         -5.31064864e-04, -7.25580223e-04],\n",
       "        [ 2.50830405e-01,  7.01814715e-02,  7.96173483e-01,\n",
       "          1.04201950e-02,  4.87081715e-01],\n",
       "        [-5.15342792e-04, -9.49846879e-05, -5.75715123e-05,\n",
       "         -3.04475778e-04, -5.89273057e-05],\n",
       "        [-5.14527391e-05, -1.45609761e-04, -3.03778272e-04,\n",
       "         -8.36145226e-05, -1.47825274e-04],\n",
       "        [ 9.98348532e-01,  4.38848286e-01,  8.10699809e-01,\n",
       "          1.67591554e-02,  4.19649725e-01],\n",
       "        [-5.41394635e-04, -9.97863971e-05, -6.04818936e-05,\n",
       "         -3.19867776e-04, -6.19062258e-05],\n",
       "        [-6.70180859e-04, -4.99574528e-04, -7.91402383e-04,\n",
       "         -5.27035954e-04, -7.20075627e-04],\n",
       "        [ 2.03419956e-01,  9.14206665e-01,  6.93423670e-01,\n",
       "          4.73888349e-01,  2.12152108e-01],\n",
       "        [ 6.54810402e-01,  7.28452420e-02,  7.62439460e-01,\n",
       "          8.33569320e-01,  2.60617495e-01],\n",
       "        [ 2.64755354e-01,  4.51404673e-01,  6.91882313e-01,\n",
       "          7.40717652e-01,  9.86630504e-01],\n",
       "        [ 4.14596875e-01,  5.22164697e-01,  5.34357701e-01,\n",
       "          2.02453449e-01,  8.29766151e-01],\n",
       "        [ 2.92840535e-01,  3.44794211e-01,  9.28994379e-01,\n",
       "          1.81887892e-01,  3.07910122e-01],\n",
       "        [ 8.75142811e-01,  9.78644744e-01,  9.25403360e-02,\n",
       "          5.57799865e-02,  5.70611848e-01],\n",
       "        [-7.06540894e-05, -1.99949026e-04, -4.17143530e-04,\n",
       "         -1.14818143e-04, -2.02991334e-04]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Un test\n",
    "alpha=10**(-3)\n",
    "Min = np.array([rd.random() for i in range(50*5)]).reshape((50,5))\n",
    "Mout = np.array([rd.random() for i in range(50*5)]).reshape((50,5))\n",
    "wout = 12\n",
    "Nwin= np.array([1,8,27,4])\n",
    "negative = 4\n",
    "hog_loop(Min,Mout,alpha,wout,Nwin,negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in Pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMQ Dupre : \n",
    "\n",
    "regarder \n",
    "// ++i i++\n",
    "   for(auto it: temp)\n",
    "       *it = 0;\n",
    "    \n",
    "for(float* it = temp; it != ; ++it)\n",
    "      *it = 0;\n",
    "      \n",
    "RMQ : peut-être pas la peine de passer random en entier à chaque loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "\n",
    "#include <time.h>\n",
    "#include <stdlib.h>\n",
    "#include <stdio.h>\n",
    "#include <curand.h>\n",
    "#include <math.h>\n",
    "\n",
    "\n",
    "\n",
    "__device__ void loop(float *Min, float *Mout, float alpha, int *Nwin, int wout, int V, int d, int N, int negative, int* random, int idx){\n",
    "    \n",
    "    /*\n",
    "    HOGWILD LOOP\n",
    "    \n",
    "    float *Min : initialisé en dehors de pycuda, poids de la PREMIERE couche du RN (attention float * et non float **) (V*d)\n",
    "    float *Mout : initialisé en dehors de pycuda, poids de la DEUXIEME couche du RN (attention float * et non float **) (V*d)\n",
    "    float alpha : learning rate\n",
    "    int *Nwin : N input du contexte de l'output\n",
    "    int wout : output\n",
    "    int V : taille du vocabulaire (nombre de mots différents)\n",
    "    int d : taille de l'espace de représentation\n",
    "    int N : taille du contexte utilisé pour l'apprentissage (de chaque coté donc 2*N en tout)\n",
    "    int negative : nb de negative utilisé pour l'apprentissage\n",
    "    int* random : entiers aléat générés en dehors (difficulté pour générer de l'aléat sur le device) pour les negative\n",
    "    int idx : indice de la parallélization (utile ?)\n",
    "    \n",
    "    Une boucle de l'Algo 1 de l'article. Permet de mettre à jour Min et Mout pour un wout (et son contexte associé).\n",
    "    */\n",
    "\n",
    "    /* Init variables */\n",
    "    float* temp;\n",
    "    temp = (float *)malloc(sizeof(float)*d);\n",
    "    int label;\n",
    "    int target_word;\n",
    "    float inn;\n",
    "    float err;\n",
    "    \n",
    "    /* Boucle principale sur les 2*N inputs*/\n",
    "    for(int i=0;i<2*N;i++){\n",
    "        int input_word = Nwin[i];\n",
    "        for(int j=0;j<d;j++){\n",
    "            temp[j]=0;\n",
    "        }\n",
    "        for(int k=0; k<negative+1;k++){\n",
    "            if (k==0){\n",
    "                target_word = wout;\n",
    "                label = 1;\n",
    "            } else {\n",
    "                /* negative sampling */\n",
    "                target_word = random[idx*negative+k-1];\n",
    "                label = 0;\n",
    "            }\n",
    "            inn = 0;\n",
    "            for(int j=0;j<d;j++){\n",
    "                inn = inn + Min[input_word*d+j]*Mout[target_word*d+j];\n",
    "            }\n",
    "            err = label-(1/(1+exp(-inn)));\n",
    "            for(int j=0;j<d;j++){\n",
    "                temp[j] = temp[j]+err*Mout[target_word*d+j];\n",
    "            }\n",
    "            for(int j=0;j<d;j++){\n",
    "                Mout[target_word*d+j] = Mout[target_word*d+j]+alpha*err*Min[input_word*d+j];\n",
    "            }  \n",
    "        }\n",
    "        for(int j=0;j<d;j++){\n",
    "            Min[input_word*d+j] = Min[input_word*d+j]+alpha*temp[j]; \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void parallel(int *X, float *Min, float* Mout, int* random, int* cst_int, float* cst_float) {\n",
    "\n",
    "    /*\n",
    "    Parallélisation\n",
    "    int *X : la matrice du hot encoding\n",
    "    float *Min : Min initialisé\n",
    "    float *Mout : Mout initialisé\n",
    "    int* random : entiers aléatoires générés hors du device\n",
    "    int* cst_int : les constantes entières utiles (V,d,negative,N)\n",
    "    float* cst_float : les constantes float utiles (alpha)\n",
    "    */\n",
    "\n",
    "    /*préparation des paramètres pour la fonction loop*/\n",
    "    \n",
    "    \n",
    "    /*constantes entières passés depuis le code python*/\n",
    "    int V = cst_int[0];\n",
    "    int d = cst_int[1];\n",
    "    int negative = cst_int[2];\n",
    "    int N = cst_int[3];\n",
    "\n",
    "    /*constante float passé depuis python*/\n",
    "    float alpha = cst_float[0];\n",
    "    \n",
    "    /*l'index correspond au thread et indique simplement le wout sur lequel on travaille*/\n",
    "    int index = threadIdx.x%(V-2*N)+N; /*+N pour éviter les effets de bord*/\n",
    "    int wout = index;\n",
    "    \n",
    "    /*Calcul des mots du contexte de wout*/\n",
    "    int *Nwin;\n",
    "    Nwin = (int *)malloc(sizeof(int)*N*2);\n",
    "    for(int i=0;i<N;i++){\n",
    "        Nwin[i]= X[index+(i-N)];\n",
    "    }\n",
    "    for(int i=0;i<N;i++){\n",
    "        Nwin[i+N]= X[index+1+i];\n",
    "    }\n",
    "\n",
    "    loop(Min,Mout,alpha,Nwin,wout,V,d,N,negative,random,index);\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation des différentes variables\n",
    "d = 10\n",
    "V = np.shape(X_hot)[1]\n",
    "negative = 5\n",
    "N = 2\n",
    "alpha = 0.001\n",
    "\n",
    "cst_int = np.array([V,d,negative,N])\n",
    "cst_float = np.array([alpha])\n",
    "\n",
    "Min = np.random.rand(V,d)\n",
    "Mout = np.random.rand(V,d)\n",
    "\n",
    "random_neg = np.random.randint(V, size=(V,negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Min = Min.astype(np.float32)\n",
    "Min_orig = copy.deepcopy(Min)\n",
    "Mout = Mout.astype(np.float32)\n",
    "Mout_orig = copy.deepcopy(Mout)\n",
    "random_neg = random_neg.astype(np.int32)\n",
    "X = X.astype(np.int32)\n",
    "cst_int = cst_int.astype(np.int32)\n",
    "cst_float = cst_float.astype(np.float32)\n",
    "\n",
    "Min_gpu = cuda.mem_alloc(Min.nbytes)\n",
    "Mout_gpu = cuda.mem_alloc(Mout.nbytes)\n",
    "random_neg_gpu = cuda.mem_alloc(random_neg.nbytes)\n",
    "X_gpu = cuda.mem_alloc(X.nbytes)\n",
    "cst_int_gpu = cuda.mem_alloc(cst_int.nbytes)\n",
    "cst_float_gpu = cuda.mem_alloc(cst_float.nbytes)\n",
    "\n",
    "cuda.memcpy_htod(Min_gpu, Min)\n",
    "cuda.memcpy_htod(Mout_gpu, Mout)\n",
    "cuda.memcpy_htod(random_neg_gpu, random_neg)\n",
    "cuda.memcpy_htod(X_gpu,X)\n",
    "cuda.memcpy_htod(cst_int_gpu,cst_int)\n",
    "cuda.memcpy_htod(cst_float_gpu,cst_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"parallel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=time.time()\n",
    "func(X_gpu,Min_gpu,Mout_gpu,random_neg_gpu,cst_int_gpu,cst_float_gpu,block=(1000,1,1))\n",
    "dt=time.time()-t0\n",
    "print(\"temps d'exécution\",dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_dtoh(Min,Min_gpu)\n",
    "cuda.memcpy_dtoh(Mout,Mout_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(Min!=Min_orig))\n",
    "print(np.sum(Mout!=Mout_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"10    : 0.00421\"\"\"\n",
    "\"\"\"100   : 0.00507\"\"\"\n",
    "\"\"\"1000  : 0.00400\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
