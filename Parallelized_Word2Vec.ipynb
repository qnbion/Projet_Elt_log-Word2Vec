{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Element Logiciel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Après\n",
       "1     avoir\n",
       "2    débuté\n",
       "3      sous\n",
       "4        le\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On travaille sur un petit texte pour commencer\n",
    "text  = open(\"data/TheBeatles.txt\", \"r\") \n",
    "text = text.readlines()[0]\n",
    "\n",
    "#Preprocessing : on supprime la ponctuation\n",
    "not_alphabet=\"'?./§,;:!»«()…-\" \n",
    "for i in not_alphabet:\n",
    "    text = text.replace(i, \"\")\n",
    "text = text.split(\" \")\n",
    "text_serie = pd.Series(text)\n",
    "text_serie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "text_lb = LabelBinarizer()\n",
    "X_hot = text_lb.fit_transform(text_serie.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 645)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_hot)\n",
    "#Les lignes sont chaque mot du texte dans l'ordre\n",
    "#Les colonnes sont les différents mots\n",
    "#ici 1300 mots dont 645 différents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.apply_along_axis(np.argmax, 1, X_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40, 171, 263, ..., 596,   0,   0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "#Pour l'application on préfère définir chaque mot par un entier (ce qui est identique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogwild implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#à modifier\n",
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def hog_loop(Min,Mout,alpha,wout,Nwin,negative):\n",
    "    #Min matrice dans V*d\n",
    "    #Mout matrice dans V*d\n",
    "    #wout vecteur dans V*1 ou entier ? dans 0:V-1\n",
    "    #nwin n vecteurs de V*1 (ie matrice de V*n) ou n entiers de 0:V-1\n",
    "    V,d=Min.shape\n",
    "    N=Nwin.shape[0]\n",
    "    for i in range(N):\n",
    "        input_word = Nwin[i]\n",
    "        temp = np.array([0]*d)\n",
    "        for k in range(negative+1):\n",
    "            if k == 0:\n",
    "                target_word = wout\n",
    "                label = 1\n",
    "            else : \n",
    "                target_word = rd.randint(0,V-1)\n",
    "                label = 0\n",
    "            inn = np.dot(Min[input_word,:],Mout[target_word,:])\n",
    "            err = label - sig(inn)\n",
    "            temp = err*Mout[target_word,:]\n",
    "            Mout[target_word,:] = alpha*err*Min[input_word,:]\n",
    "        Min[input_word,:]=alpha*temp\n",
    "    return(Min,Mout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6.57457376e-01,  3.56340910e-01,  5.45804540e-02,\n",
       "          2.97114601e-01,  1.41576195e-01],\n",
       "        [-2.24044509e-04, -4.34140822e-04, -1.74990176e-04,\n",
       "         -1.87523486e-04, -1.14543591e-05],\n",
       "        [ 1.57170980e-01,  7.30593566e-01,  6.24539064e-01,\n",
       "          2.77103837e-01,  2.60055955e-01],\n",
       "        [ 3.85330960e-01,  7.16706257e-01,  2.43579764e-01,\n",
       "          5.30067045e-01,  5.37585231e-01],\n",
       "        [-3.75435978e-04, -5.01598126e-04, -8.62691310e-05,\n",
       "         -7.59225508e-04, -1.23424273e-06],\n",
       "        [ 6.46933580e-01,  9.98439651e-01,  9.40621368e-01,\n",
       "          7.36561506e-01,  8.79106906e-01],\n",
       "        [ 3.43116825e-01,  6.52921598e-01,  1.37278205e-01,\n",
       "          9.24534236e-01,  5.80907634e-01],\n",
       "        [ 5.86096814e-01,  3.39286250e-01,  6.15573075e-01,\n",
       "          9.88588941e-01,  7.47260039e-01],\n",
       "        [-5.73898284e-04, -5.72229262e-04, -4.37188570e-04,\n",
       "         -1.14938143e-04, -5.98802651e-05],\n",
       "        [ 2.98493294e-01,  1.10234961e-01,  8.62868526e-01,\n",
       "          4.42481666e-01,  3.92362857e-01],\n",
       "        [ 2.12453216e-01,  5.03096214e-01,  3.11540528e-01,\n",
       "          5.84550448e-01,  2.65029292e-01],\n",
       "        [ 9.92793359e-01,  9.39857172e-01,  6.78992878e-01,\n",
       "          4.44323298e-02,  7.59042421e-01],\n",
       "        [ 4.87826703e-02,  1.98739080e-01,  9.79414843e-01,\n",
       "          4.28213801e-01,  5.60684701e-01],\n",
       "        [ 6.40295465e-01,  1.84425110e-01,  7.82922681e-01,\n",
       "          7.24716299e-01,  5.62912429e-01],\n",
       "        [ 7.00119430e-01,  4.86553032e-01,  5.45229317e-01,\n",
       "          2.25274918e-01,  2.64141419e-01],\n",
       "        [ 4.18566028e-01,  5.31739383e-01,  5.95840709e-01,\n",
       "          9.85391382e-01,  9.57373491e-01],\n",
       "        [ 5.66219375e-01,  1.28206464e-02,  3.14389356e-01,\n",
       "          4.49489315e-01,  7.41667696e-01],\n",
       "        [ 4.73192174e-02,  2.75372112e-01,  8.16940122e-01,\n",
       "          9.88321567e-01,  3.65625437e-01],\n",
       "        [ 4.48190138e-01,  4.43914941e-01,  2.76076578e-01,\n",
       "          2.37444750e-01,  8.63297560e-01],\n",
       "        [ 5.99161461e-01,  6.35442845e-01,  6.54745402e-01,\n",
       "          5.31144882e-01,  5.89423399e-01],\n",
       "        [ 3.91227073e-01,  2.69265516e-01,  7.54893829e-01,\n",
       "          8.35924232e-02,  9.24103014e-01],\n",
       "        [ 7.57321296e-01,  4.07298296e-01,  4.87145289e-01,\n",
       "          4.49087122e-01,  7.47523772e-01],\n",
       "        [ 8.97737168e-01,  9.31490762e-01,  7.28931700e-01,\n",
       "          2.51439197e-01,  6.76150588e-01],\n",
       "        [ 7.82519506e-01,  4.13342797e-01,  4.20122367e-01,\n",
       "          6.38854654e-01,  2.51683771e-01],\n",
       "        [ 1.53575230e-01,  3.23884251e-01,  8.37495365e-02,\n",
       "          2.86919179e-01,  3.25218413e-01],\n",
       "        [ 8.24504863e-01,  1.57453058e-01,  4.85563062e-01,\n",
       "          4.98247561e-01,  2.16906654e-01],\n",
       "        [ 8.63915722e-01,  5.07725059e-01,  1.14095964e-01,\n",
       "          6.19368375e-01,  3.02571879e-01],\n",
       "        [ 3.21313589e-07,  2.64261164e-07,  6.51387788e-08,\n",
       "          3.68612757e-08,  3.37090326e-07],\n",
       "        [ 6.90014381e-01,  7.79364262e-01,  1.64969098e-01,\n",
       "          6.57726787e-01,  2.81348119e-01],\n",
       "        [ 9.82234523e-01,  7.96746404e-01,  7.73334210e-01,\n",
       "          6.62618921e-01,  4.09921332e-01],\n",
       "        [ 6.58938300e-01,  6.93843457e-01,  9.91476687e-02,\n",
       "          6.26294299e-01,  5.69082051e-01],\n",
       "        [ 8.27622832e-01,  5.39036409e-01,  8.45327487e-01,\n",
       "          4.01078036e-01,  4.56428832e-01],\n",
       "        [ 4.70348832e-01,  7.10959400e-01,  4.43417795e-01,\n",
       "          1.89097222e-01,  7.23914270e-01],\n",
       "        [ 3.30729601e-01,  5.63370406e-01,  3.03936434e-01,\n",
       "          8.08407589e-02,  3.11422642e-01],\n",
       "        [ 5.78541236e-01,  7.23841373e-01,  7.95959124e-01,\n",
       "          7.84722765e-01,  6.00988025e-01],\n",
       "        [ 9.04207155e-01,  5.82880199e-02,  4.55952813e-01,\n",
       "          9.51620625e-01,  1.37067163e-01],\n",
       "        [ 1.42678329e-01,  5.21495749e-01,  7.59489156e-01,\n",
       "          9.55723742e-01,  2.81789455e-01],\n",
       "        [ 9.00659456e-01,  1.97291566e-01,  4.46368348e-01,\n",
       "          8.50155628e-02,  9.69120822e-01],\n",
       "        [ 2.58822512e-01,  4.69847932e-01,  1.53319418e-01,\n",
       "          3.74069038e-01,  9.87678360e-01],\n",
       "        [ 3.15744251e-01,  8.32439700e-01,  8.64259062e-01,\n",
       "          9.93726335e-01,  8.40157015e-01],\n",
       "        [ 2.80407203e-01,  7.97241173e-02,  7.30494882e-02,\n",
       "          4.94796684e-01,  3.62893230e-01],\n",
       "        [ 8.04695066e-01,  7.57305063e-01,  3.99298227e-01,\n",
       "          5.19158972e-01,  9.44293480e-01],\n",
       "        [ 5.59436717e-01,  4.02003212e-01,  8.38295964e-02,\n",
       "          2.89677531e-01,  4.05710275e-01],\n",
       "        [ 6.12787107e-01,  4.40828265e-01,  4.63407897e-02,\n",
       "          7.87292555e-01,  3.05786500e-01],\n",
       "        [ 7.79352808e-01,  4.36243682e-01,  1.75906854e-02,\n",
       "          2.36912872e-02,  3.05953761e-01],\n",
       "        [ 5.79548610e-01,  1.42577081e-01,  1.38941577e-01,\n",
       "          5.97228302e-01,  8.08253752e-01],\n",
       "        [ 4.32747015e-01,  1.55569674e-01,  5.94080733e-01,\n",
       "          9.79119956e-01,  1.64190792e-01],\n",
       "        [ 6.41540592e-01,  9.96315329e-03,  8.38891113e-01,\n",
       "          2.16194888e-01,  5.89228313e-01],\n",
       "        [ 1.85707426e-01,  1.67081624e-01,  1.89558947e-01,\n",
       "          5.79762078e-01,  2.89969659e-01],\n",
       "        [ 1.83824576e-01,  3.88388079e-01,  6.47904697e-01,\n",
       "          4.81772269e-02,  9.00488901e-01]]),\n",
       " array([[-8.56450783e-05, -4.92684667e-06, -1.12297587e-04,\n",
       "         -4.13611625e-04, -2.80873608e-05],\n",
       "        [ 5.59863064e-01,  7.83554057e-01,  5.90185583e-01,\n",
       "          3.89373718e-01,  3.08337027e-01],\n",
       "        [ 7.11524857e-02,  8.21393345e-01,  5.50504461e-01,\n",
       "          1.26085104e-01,  5.97215728e-01],\n",
       "        [ 7.60036117e-01,  8.14708266e-01,  9.75815678e-02,\n",
       "          5.88757521e-01,  9.11731070e-01],\n",
       "        [ 1.49542115e-01,  4.97878395e-01,  7.62815038e-01,\n",
       "          5.10128125e-01,  4.94694001e-01],\n",
       "        [-3.51459739e-04, -2.55609592e-04, -3.76315113e-04,\n",
       "         -7.86319869e-04, -6.01335631e-04],\n",
       "        [ 6.54021903e-01,  9.42624918e-01,  7.16687159e-01,\n",
       "          7.72095365e-01,  4.61939032e-01],\n",
       "        [ 3.04303775e-01,  4.82958336e-01,  7.62387550e-01,\n",
       "          9.09314934e-01,  4.08944901e-01],\n",
       "        [ 6.19768766e-01,  5.55107641e-01,  7.21655286e-01,\n",
       "          8.20839874e-01,  6.11796514e-01],\n",
       "        [-1.02645107e-04, -5.90479584e-06, -1.34587976e-04,\n",
       "         -4.95711023e-04, -3.36625314e-05],\n",
       "        [ 4.69709157e-01,  7.33675557e-01,  6.57705649e-01,\n",
       "          2.15388707e-02,  6.63448516e-01],\n",
       "        [ 3.92605010e-01,  6.29513199e-01,  4.85156873e-01,\n",
       "          2.72519013e-01,  7.29480329e-02],\n",
       "        [ 2.03848782e-04,  1.48255115e-04,  2.18265050e-04,\n",
       "          4.56070298e-04,  3.48778317e-04],\n",
       "        [ 2.53984203e-01,  3.05211614e-02,  2.09263665e-01,\n",
       "          2.11328950e-01,  7.39482211e-01],\n",
       "        [ 2.40932188e-01,  3.83374150e-01,  5.77500636e-01,\n",
       "          4.88898070e-01,  5.10148068e-01],\n",
       "        [ 1.67620367e-02,  4.91770098e-01,  1.10939934e-01,\n",
       "          7.94470440e-01,  4.82345933e-01],\n",
       "        [ 7.63983668e-01,  4.31860515e-01,  9.78085764e-01,\n",
       "          3.81272673e-01,  9.42854038e-01],\n",
       "        [ 6.92861652e-01,  6.34719596e-01,  1.96275037e-01,\n",
       "          3.69377881e-01,  5.65517888e-01],\n",
       "        [ 2.04682138e-01,  9.50915572e-02,  8.00383495e-01,\n",
       "          7.83105463e-01,  1.11203676e-01],\n",
       "        [ 1.25618657e-01,  7.09929034e-02,  9.64451625e-01,\n",
       "          1.92867920e-01,  6.21371637e-01],\n",
       "        [-2.03780017e-04, -1.48205104e-04, -2.18191422e-04,\n",
       "         -4.55916451e-04, -3.48660663e-04],\n",
       "        [ 6.90112216e-01,  7.61062197e-01,  9.39942203e-01,\n",
       "          1.34109464e-01,  3.66113749e-01],\n",
       "        [ 5.45373785e-01,  4.74124438e-01,  7.17608764e-01,\n",
       "          4.44028029e-01,  7.05588687e-02],\n",
       "        [ 7.74153232e-01,  6.93391897e-01,  2.41491963e-01,\n",
       "          4.62215746e-01,  1.98336037e-02],\n",
       "        [-4.65972930e-04, -8.06623133e-06, -1.36258460e-05,\n",
       "         -9.91116476e-05, -8.23310284e-05],\n",
       "        [ 2.46282706e-01,  1.50673138e-01,  2.64422757e-01,\n",
       "          9.43973734e-01,  3.67707394e-01],\n",
       "        [ 5.04821845e-01,  2.14142205e-01,  4.43808460e-02,\n",
       "          5.78461157e-01,  7.94806359e-01],\n",
       "        [ 2.64926708e-01,  5.21499476e-01,  1.65149681e-01,\n",
       "          3.88231607e-01,  2.12293634e-01],\n",
       "        [ 8.16868749e-01,  1.51440423e-01,  8.78133542e-01,\n",
       "          7.26663122e-01,  2.67882375e-01],\n",
       "        [ 5.84325676e-01,  7.44714489e-01,  9.26780308e-01,\n",
       "          9.24858999e-01,  7.37681727e-01],\n",
       "        [ 3.15455199e-01,  3.55109514e-01,  8.85432818e-01,\n",
       "          2.78527609e-01,  6.85054966e-01],\n",
       "        [-4.84361780e-04, -8.38455180e-06, -1.41635674e-05,\n",
       "         -1.03022925e-04, -8.55800862e-05],\n",
       "        [-6.39330339e-04, -5.25810876e-04, -1.29609201e-04,\n",
       "         -7.33443363e-05, -6.70721936e-04],\n",
       "        [-1.01559056e-04, -5.84231933e-06, -1.33163950e-04,\n",
       "         -4.90466084e-04, -3.33063604e-05],\n",
       "        [-6.58638536e-04, -5.41690711e-04, -1.33523484e-04,\n",
       "         -7.55593835e-05, -6.90978181e-04],\n",
       "        [ 8.55817847e-01,  3.91791594e-01,  5.86238397e-01,\n",
       "          7.75385731e-01,  7.43909534e-01],\n",
       "        [ 2.68962160e-01,  1.10110869e-01,  9.53270591e-01,\n",
       "          9.38023371e-02,  1.12663386e-01],\n",
       "        [ 8.02393321e-01,  5.41594172e-01,  6.97948452e-01,\n",
       "          4.17018042e-01,  1.67665842e-01],\n",
       "        [ 1.93247137e-01,  4.58302501e-01,  4.43130261e-01,\n",
       "          5.92432251e-01,  2.30782346e-01],\n",
       "        [ 6.19818549e-01,  2.05901403e-01,  7.62365623e-01,\n",
       "          7.51716723e-01,  2.90538375e-01],\n",
       "        [ 2.23821868e-01,  6.00703667e-01,  2.59693317e-01,\n",
       "          1.52927697e-01,  8.64921464e-01],\n",
       "        [-4.60270893e-04, -7.96752615e-06, -1.34591087e-05,\n",
       "         -9.78988341e-05, -8.13235568e-05],\n",
       "        [-3.21275046e-04, -2.33656873e-04, -3.43995747e-04,\n",
       "         -7.18787744e-04, -5.49690652e-04],\n",
       "        [ 3.87611779e-01,  8.40812788e-01,  3.71345690e-01,\n",
       "          1.23908986e-01,  2.96357668e-01],\n",
       "        [ 1.08863725e-01,  2.65436313e-01,  5.75773347e-02,\n",
       "          8.85523873e-01,  1.19291316e-01],\n",
       "        [-4.11930679e-04, -3.38788288e-04, -8.35092641e-05,\n",
       "         -4.72569193e-05, -4.32156783e-04],\n",
       "        [-9.76328392e-05, -5.61645851e-06, -1.28015905e-04,\n",
       "         -4.71504938e-04, -3.20187550e-05],\n",
       "        [ 2.69238093e-01,  4.12789376e-01,  1.44453745e-01,\n",
       "          3.14095255e-01,  2.30982302e-01],\n",
       "        [-4.25119657e-04, -7.35904015e-06, -1.24312264e-05,\n",
       "         -9.04222261e-05, -7.51128152e-05],\n",
       "        [ 2.38952521e-01,  6.53552341e-01,  9.61662655e-02,\n",
       "          2.41298224e-01,  5.06360296e-01]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Un test\n",
    "alpha=10**(-3)\n",
    "Min = np.array([rd.random() for i in range(50*5)]).reshape((50,5))\n",
    "Mout = np.array([rd.random() for i in range(50*5)]).reshape((50,5))\n",
    "wout = 12\n",
    "Nwin= np.array([1,8,27,4])\n",
    "negative = 4\n",
    "hog_loop(Min,Mout,alpha,wout,Nwin,negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in Pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMQ Dupre : \n",
    "\n",
    "regarder \n",
    "// ++i i++\n",
    "   for(auto it: temp)\n",
    "       *it = 0;\n",
    "    \n",
    "for(float* it = temp; it != ; ++it)\n",
    "      *it = 0;\n",
    "      \n",
    "RMQ : peut-être pas la peine de passer random en entier à chaque loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quent\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:113: UserWarning: The CUDA compiler succeeded, but said the following:\n",
      "kernel.cu\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "\n",
    "#include <time.h>\n",
    "#include <stdlib.h>\n",
    "#include <stdio.h>\n",
    "#include <curand.h>\n",
    "#include <math.h>\n",
    "\n",
    "\n",
    "\n",
    "__device__ void loop(float *Min, float *Mout, float alpha, int *Nwin, int wout, int V, int d, int N, int negative, int* random, int idx){\n",
    "    \n",
    "    /*\n",
    "    HOGWILD LOOP\n",
    "    \n",
    "    float *Min : initialisé en dehors de pycuda, poids de la PREMIERE couche du RN (attention float * et non float **) (V*d)\n",
    "    float *Mout : initialisé en dehors de pycuda, poids de la DEUXIEME couche du RN (attention float * et non float **) (V*d)\n",
    "    float alpha : learning rate\n",
    "    int *Nwin : N input du contexte de l'output\n",
    "    int wout : output\n",
    "    int V : taille du vocabulaire (nombre de mots différents)\n",
    "    int d : taille de l'espace de représentation\n",
    "    int N : taille du contexte utilisé pour l'apprentissage (de chaque coté donc 2*N en tout)\n",
    "    int negative : nb de negative utilisé pour l'apprentissage\n",
    "    int* random : entiers aléat générés en dehors (difficulté pour générer de l'aléat sur le device) pour les negative\n",
    "    int idx : indice de la parallélization (utile ?)\n",
    "    \n",
    "    Une boucle de l'Algo 1 de l'article. Permet de mettre à jour Min et Mout pour un wout (et son contexte associé).\n",
    "    */\n",
    "\n",
    "    /* Init variables */\n",
    "    float* temp;\n",
    "    temp = (float *)malloc(sizeof(float)*d);\n",
    "    int label;\n",
    "    int target_word;\n",
    "    float inn;\n",
    "    float err;\n",
    "    \n",
    "    /* Boucle principale sur les 2*N inputs*/\n",
    "    for(int i=0;i<2*N;i++){\n",
    "        int input_word = Nwin[i];\n",
    "        for(int j=0;j<d;j++){\n",
    "            temp[j]=0;\n",
    "        }\n",
    "        for(int k=0; k<negative+1;k++){\n",
    "            if (k==0){\n",
    "                target_word = wout;\n",
    "                label = 1;\n",
    "            } else {\n",
    "                /* negative sampling */\n",
    "                target_word = random[idx*V+k-1];\n",
    "                label = 0;\n",
    "            }\n",
    "            inn = 0;\n",
    "            for(int j=0;j<d;j++){\n",
    "                inn = inn + Min[input_word*V+j]*Mout[target_word*V+j];\n",
    "            }\n",
    "            err = label-(1/(1+exp(-inn)));\n",
    "            for(int j=0;j<d;j++){\n",
    "                temp[j] = temp[j]+err*Mout[target_word*V+j];\n",
    "            }\n",
    "            for(int j=0;j<d;j++){\n",
    "                Mout[target_word*V+j] = Mout[target_word*V+j]+alpha*err*Min[input_word*V+j];\n",
    "            }  \n",
    "        }\n",
    "        for(int j=0;j<d;j++){\n",
    "            Min[input_word*V+j] = Min[input_word*V+j]+alpha*temp[j]; \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void parallel(int *X, float *Min, float* Mout, int* random, int* cst_int, float* cst_float) {\n",
    "\n",
    "    /*\n",
    "    Parallélisation\n",
    "    int *X : la matrice du hot encoding\n",
    "    float *Min : Min initialisé\n",
    "    float *Mout : Mout initialisé\n",
    "    int* random : entiers aléatoires générés hors du device\n",
    "    int* cst_int : les constantes entières utiles (V,d,negative,N)\n",
    "    float* cst_float : les constantes float utiles (alpha)\n",
    "    */\n",
    "\n",
    "    /*préparation des paramètres pour la fonction loop*/\n",
    "    \n",
    "    \n",
    "    /*constantes entières passés depuis le code python*/\n",
    "    int V = cst_int[0];\n",
    "    int d = cst_int[1];\n",
    "    int negative = cst_int[2];\n",
    "    int N = cst_int[3];\n",
    "\n",
    "    /*constante float passé depuis python*/\n",
    "    float alpha = cst_float[0];\n",
    "    \n",
    "    /*l'index correspond au thread et indique simplement le wout sur lequel on travaille*/\n",
    "    int index = threadIdx.x+N; /*+N pour éviter les effets de bord*/\n",
    "    int wout = index;\n",
    "    \n",
    "    /*Calcul des mots du contexte de wout*/\n",
    "    int *Nwin;\n",
    "    Nwin = (int *)malloc(sizeof(int)*N*2);\n",
    "    for(int i=0;i<N;i++){\n",
    "        Nwin[i]= X[index+(i-N)];\n",
    "    }\n",
    "    for(int i=0;i<N;i++){\n",
    "        Nwin[i+N]= X[index+1+i];\n",
    "    }\n",
    "\n",
    "    loop(Min,Mout,alpha,Nwin,wout,V,d,N,negative,random,index);\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation des différentes variables\n",
    "d = 10\n",
    "V = np.shape(X_hot)[1]\n",
    "negative = 5\n",
    "N = 2\n",
    "alpha = 0.001\n",
    "\n",
    "cst_int = np.array([V,d,negative,N])\n",
    "cst_float = np.array([alpha])\n",
    "\n",
    "Min = np.random.rand(V,d)\n",
    "Mout = np.random.rand(V,d)\n",
    "\n",
    "random_neg = np.random.randint(V, size=(V,negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Min = Min.astype(np.float32)\n",
    "Min_orig = copy.deepcopy(Min)\n",
    "Mout = Mout.astype(np.float32)\n",
    "Mout_orig = copy.deepcopy(Mout)\n",
    "random_neg = random_neg.astype(np.int32)\n",
    "X = X.astype(np.int32)\n",
    "cst_int = cst_int.astype(np.int32)\n",
    "cst_float = cst_float.astype(np.float32)\n",
    "\n",
    "Min_gpu = cuda.mem_alloc(Min.nbytes)\n",
    "Mout_gpu = cuda.mem_alloc(Mout.nbytes)\n",
    "random_neg_gpu = cuda.mem_alloc(random_neg.nbytes)\n",
    "X_gpu = cuda.mem_alloc(X.nbytes)\n",
    "cst_int_gpu = cuda.mem_alloc(cst_int.nbytes)\n",
    "cst_float_gpu = cuda.mem_alloc(cst_float.nbytes)\n",
    "\n",
    "cuda.memcpy_htod(Min_gpu, Min)\n",
    "cuda.memcpy_htod(Mout_gpu, Mout)\n",
    "cuda.memcpy_htod(random_neg_gpu, random_neg)\n",
    "cuda.memcpy_htod(X_gpu,X)\n",
    "cuda.memcpy_htod(cst_int_gpu,cst_int)\n",
    "cuda.memcpy_htod(cst_float_gpu,cst_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"parallel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(X_gpu,Min_gpu,Mout_gpu,random_neg_gpu,cst_int_gpu,cst_float_gpu,block=(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_dtoh(Min,Min_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Min!=Min_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2685476 , 0.9198131 , 0.84947795, ..., 0.40636152, 0.90575653,\n",
       "        0.47231206],\n",
       "       [0.22858192, 0.22459435, 0.05354735, ..., 0.09916596, 0.81183684,\n",
       "        0.35060242],\n",
       "       [0.37956896, 0.03998403, 0.1090909 , ..., 0.3231697 , 0.81569666,\n",
       "        0.2133335 ],\n",
       "       ...,\n",
       "       [0.998923  , 0.14766037, 0.15258278, ..., 0.8069735 , 0.18269418,\n",
       "        0.06957479],\n",
       "       [0.29577845, 0.03093859, 0.06055066, ..., 0.08497865, 0.79866123,\n",
       "        0.01747274],\n",
       "       [0.29132888, 0.5988786 , 0.6840373 , ..., 0.4526808 , 0.25655496,\n",
       "        0.04156274]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
