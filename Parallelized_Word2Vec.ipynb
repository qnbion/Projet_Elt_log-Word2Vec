{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Element Logiciel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Après\n",
       "1     avoir\n",
       "2    débuté\n",
       "3      sous\n",
       "4        le\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On travaille sur un petit texte pour commencer\n",
    "text  = open(\"data/TheBeatles.txt\", \"r\") \n",
    "text = text.readlines()[0]\n",
    "\n",
    "#Preprocessing : on supprime la ponctuation\n",
    "not_alphabet=\"'?./§,;:!»«()…-\" \n",
    "for i in not_alphabet:\n",
    "    text = text.replace(i, \"\")\n",
    "text = text.split(\" \")\n",
    "text_serie = pd.Series(text)\n",
    "text_serie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "text_lb = LabelBinarizer()\n",
    "X_hot = text_lb.fit_transform(text_serie.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 645)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_hot)\n",
    "#Les lignes sont chaque mot du texte dans l'ordre\n",
    "#Les colonnes sont les différents mots\n",
    "#ici 1300 mots dont 645 différents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.apply_along_axis(np.argmax, 1, X_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40, 171, 263, ..., 596,   0,   0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "#Pour l'application on préfère définir chaque mot par un entier (ce qui est identique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogwild implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#à modifier\n",
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def hog_loop(Min,Mout,alpha,wout,Nwin,negative):\n",
    "    #Min matrice dans V*d\n",
    "    #Mout matrice dans V*d\n",
    "    #wout vecteur dans V*1 ou entier ? dans 0:V-1\n",
    "    #nwin n vecteurs de V*1 (ie matrice de V*n) ou n entiers de 0:V-1\n",
    "    V,d=Min.shape\n",
    "    N=Nwin.shape[0]\n",
    "    for i in range(N):\n",
    "        input_word = Nwin[i]\n",
    "        temp = np.array([0]*d)\n",
    "        for k in range(negative+1):\n",
    "            if k == 0:\n",
    "                target_word = wout\n",
    "                label = 1\n",
    "            else : \n",
    "                target_word = rd.randint(0,V-1)\n",
    "                label = 0\n",
    "            inn = np.dot(Min[input_word,:],Mout[target_word,:])\n",
    "            err = label - sig(inn)\n",
    "            temp = err*Mout[target_word,:]\n",
    "            Mout[target_word,:] = alpha*err*Min[input_word,:]\n",
    "        Min[input_word,:]=alpha*temp\n",
    "    return(Min,Mout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5.61261596e-02,  5.09498761e-01,  4.44481245e-01,\n",
       "          7.31734567e-01,  6.64943600e-01],\n",
       "        [-3.72093841e-04, -4.14854147e-05, -3.01536942e-04,\n",
       "         -4.35510735e-04, -1.22340393e-04],\n",
       "        [ 5.59782209e-01,  3.68464106e-01,  4.54759580e-01,\n",
       "          8.74249170e-01,  6.90428501e-01],\n",
       "        [ 2.25292127e-01,  8.76824448e-01,  2.36051431e-01,\n",
       "          1.02314982e-01,  7.28965088e-02],\n",
       "        [ 1.35481184e-08,  2.58750512e-07,  3.37795720e-07,\n",
       "          1.25186210e-07,  2.09784338e-07],\n",
       "        [ 3.93491087e-02,  1.23549268e-01,  1.27318856e-01,\n",
       "          7.98951919e-01,  2.96498680e-01],\n",
       "        [ 3.72781607e-01,  8.70029721e-01,  9.09880425e-01,\n",
       "          9.03354635e-01,  2.32403729e-01],\n",
       "        [ 5.62360522e-01,  7.99426583e-01,  8.68153776e-02,\n",
       "          1.92433797e-01,  8.38023593e-02],\n",
       "        [-7.47730500e-05, -5.06962138e-04, -7.19844152e-04,\n",
       "         -3.88831761e-04, -6.97081322e-05],\n",
       "        [ 5.12021280e-01,  9.92012529e-01,  8.23149257e-01,\n",
       "          7.93341432e-01,  9.65372076e-02],\n",
       "        [ 3.25872626e-01,  6.74001872e-01,  3.54542865e-01,\n",
       "          1.69456857e-01,  1.39210338e-01],\n",
       "        [ 6.69884061e-01,  3.07662965e-01,  1.32837400e-01,\n",
       "          7.41515416e-01,  9.03555293e-01],\n",
       "        [ 3.11155809e-02,  2.31558957e-01,  8.92552590e-01,\n",
       "          5.10381230e-01,  2.06525026e-01],\n",
       "        [ 7.34549637e-02,  5.00522351e-02,  8.24404946e-01,\n",
       "          9.89512492e-01,  3.49327160e-01],\n",
       "        [ 2.94974528e-01,  8.21209980e-01,  2.87482495e-01,\n",
       "          7.89262190e-01,  6.41652611e-01],\n",
       "        [ 8.03902749e-01,  6.44476488e-01,  2.78626043e-01,\n",
       "          9.30515196e-01,  1.59833237e-01],\n",
       "        [ 9.25034221e-01,  9.21778628e-01,  4.82500162e-01,\n",
       "          6.13306840e-01,  1.45837821e-01],\n",
       "        [ 2.75206483e-01,  1.54533485e-01,  3.41856831e-01,\n",
       "          5.37189065e-01,  9.82726861e-01],\n",
       "        [ 6.04530851e-01,  6.55411291e-01,  9.39566757e-01,\n",
       "          8.46830489e-01,  3.67363373e-01],\n",
       "        [ 2.42073185e-01,  5.44430029e-01,  2.04159416e-01,\n",
       "          1.28334296e-01,  8.07186778e-01],\n",
       "        [ 6.49254058e-01,  4.41834297e-01,  4.35217790e-01,\n",
       "          4.37149977e-01,  3.45522608e-01],\n",
       "        [ 3.42280096e-01,  5.15854790e-01,  7.11089008e-01,\n",
       "          4.55563350e-01,  5.73203921e-01],\n",
       "        [ 5.06228702e-01,  8.15468662e-01,  7.79940473e-01,\n",
       "          6.89068723e-01,  4.74048466e-01],\n",
       "        [ 9.21223044e-01,  6.88086798e-01,  8.82248291e-01,\n",
       "          9.41988049e-01,  7.85095602e-01],\n",
       "        [ 5.85500037e-01,  4.37448823e-01,  9.34378541e-01,\n",
       "          4.65770449e-01,  5.14643003e-01],\n",
       "        [ 1.78818256e-01,  6.72968974e-02,  3.44320401e-02,\n",
       "          7.68965067e-01,  2.45827338e-01],\n",
       "        [ 5.53201162e-01,  8.61980136e-01,  2.98899693e-01,\n",
       "          2.95330356e-01,  5.11891351e-01],\n",
       "        [-6.11073649e-04, -7.04549781e-04, -2.13358329e-04,\n",
       "         -1.53338167e-04, -7.00441226e-04],\n",
       "        [ 5.67286224e-01,  9.43497838e-01,  1.92514721e-01,\n",
       "          1.78858505e-01,  8.06611273e-01],\n",
       "        [ 6.80255016e-01,  9.67294925e-01,  1.78020083e-01,\n",
       "          7.36096487e-01,  5.62841574e-01],\n",
       "        [ 8.58842229e-01,  5.02287097e-01,  9.25892244e-01,\n",
       "          1.12197958e-01,  6.47253331e-01],\n",
       "        [ 3.10560541e-01,  2.35717536e-01,  3.17158049e-02,\n",
       "          4.29337181e-01,  2.78031959e-01],\n",
       "        [ 6.62742311e-01,  3.95804304e-01,  3.63971818e-01,\n",
       "          5.68827995e-01,  7.28020416e-01],\n",
       "        [ 8.74908442e-01,  8.11636292e-01,  8.80391032e-01,\n",
       "          7.56310306e-01,  8.13683279e-01],\n",
       "        [ 5.06067548e-01,  5.46151517e-01,  9.74223199e-02,\n",
       "          4.12587027e-01,  2.94054282e-01],\n",
       "        [ 2.48460565e-01,  9.89149219e-01,  1.39919277e-01,\n",
       "          5.83080509e-01,  6.13912105e-01],\n",
       "        [ 9.26288346e-01,  1.97720746e-01,  7.61394212e-01,\n",
       "          7.30213126e-01,  4.04479743e-01],\n",
       "        [ 1.83990759e-01,  6.60919786e-01,  4.20486820e-01,\n",
       "          8.20387834e-01,  4.27989742e-01],\n",
       "        [ 3.04458512e-01,  1.51329915e-01,  7.32655754e-01,\n",
       "          2.00638240e-02,  3.23782613e-01],\n",
       "        [ 3.80243028e-01,  2.60303730e-01,  3.86037191e-02,\n",
       "          5.17354594e-01,  5.42157258e-01],\n",
       "        [ 1.47543386e-01,  8.23017521e-01,  6.16997442e-01,\n",
       "          7.45715794e-01,  4.72873814e-01],\n",
       "        [ 9.56063245e-01,  1.58586569e-01,  1.52159861e-01,\n",
       "          6.04301166e-01,  1.93639962e-01],\n",
       "        [ 2.29119031e-01,  4.46916715e-01,  8.92909334e-01,\n",
       "          2.45972381e-01,  2.36641479e-01],\n",
       "        [ 6.70188700e-01,  3.75097983e-01,  8.87899994e-01,\n",
       "          6.97418355e-01,  9.09253391e-01],\n",
       "        [ 5.59546711e-01,  2.23219968e-03,  5.20887381e-01,\n",
       "          8.37816429e-01,  2.08850462e-01],\n",
       "        [ 2.81294454e-01,  1.76488336e-01,  5.96821946e-01,\n",
       "          3.16397778e-01,  7.23248500e-01],\n",
       "        [ 1.31168501e-02,  6.96621190e-01,  1.81358902e-01,\n",
       "          3.72921533e-01,  8.46384158e-01],\n",
       "        [ 7.82566506e-01,  7.73118445e-01,  2.68581120e-01,\n",
       "          1.90983363e-01,  4.97985497e-02],\n",
       "        [ 1.15133392e-01,  9.22899542e-01,  9.23095373e-01,\n",
       "          5.31391542e-01,  9.03409076e-01],\n",
       "        [ 2.52167476e-01,  4.08290010e-01,  2.03326271e-01,\n",
       "          2.27048726e-01,  8.72215034e-01]]),\n",
       " array([[-1.87033269e-04, -3.97400153e-04, -4.07307696e-04,\n",
       "         -5.64247617e-04, -2.21227080e-04],\n",
       "        [ 8.94339509e-01,  1.90030007e-01,  1.53679378e-01,\n",
       "          3.28074562e-01,  1.95787723e-01],\n",
       "        [ 4.01098538e-01,  4.17257321e-01,  3.56260237e-01,\n",
       "          3.77005969e-01,  3.40788880e-01],\n",
       "        [ 4.70529259e-01,  7.55822740e-01,  5.69786561e-02,\n",
       "          7.22796252e-01,  9.68186735e-01],\n",
       "        [ 6.38135141e-01,  2.97319746e-01,  8.64492899e-01,\n",
       "          9.22854911e-01,  1.42067536e-02],\n",
       "        [ 9.20687075e-01,  5.86650786e-01,  6.16716880e-01,\n",
       "          4.67712873e-01,  2.51572901e-01],\n",
       "        [ 9.65743116e-01,  6.26918870e-02,  2.25112849e-01,\n",
       "          6.66499530e-02,  3.46482204e-01],\n",
       "        [ 7.60799510e-01,  1.27899037e-01,  3.03249806e-01,\n",
       "          6.18636903e-02,  2.04628122e-01],\n",
       "        [-4.65575461e-04, -1.40958164e-04, -2.76992424e-04,\n",
       "         -4.13593931e-04, -4.40952180e-05],\n",
       "        [ 4.88741749e-01,  1.90380662e-01,  7.75986703e-01,\n",
       "          3.13686273e-01,  3.63835878e-01],\n",
       "        [-2.26947575e-04, -4.82208333e-04, -4.94230220e-04,\n",
       "         -6.84662300e-04, -2.68438601e-04],\n",
       "        [ 9.58067560e-01,  8.70511815e-03,  4.55068445e-01,\n",
       "          1.26430314e-01,  6.53610415e-01],\n",
       "        [ 4.65643802e-04,  1.40978855e-04,  2.77033083e-04,\n",
       "          4.13654642e-04,  4.41016906e-05],\n",
       "        [ 7.33440261e-01,  4.89034289e-01,  8.52053420e-01,\n",
       "          3.14154397e-01,  6.20703693e-01],\n",
       "        [-2.13212266e-04, -3.89359539e-04, -1.64134019e-04,\n",
       "         -4.42617013e-04, -4.56792778e-04],\n",
       "        [-2.21375610e-04, -4.70369263e-04, -4.82095991e-04,\n",
       "         -6.67852626e-04, -2.61847958e-04],\n",
       "        [-2.40198647e-04, -4.38640968e-04, -1.84908543e-04,\n",
       "         -4.98639267e-04, -5.14609266e-04],\n",
       "        [ 1.98032891e-01,  2.12599738e-01,  4.21628425e-01,\n",
       "          5.56459314e-02,  1.05818456e-02],\n",
       "        [ 7.09548926e-01,  4.98523638e-01,  8.25848668e-01,\n",
       "          9.64856912e-02,  7.00491428e-01],\n",
       "        [-4.65412226e-04, -1.40908743e-04, -2.76895308e-04,\n",
       "         -4.13448922e-04, -4.40797578e-05],\n",
       "        [ 2.93586219e-01,  8.90742974e-01,  2.57631027e-02,\n",
       "          4.27250974e-01,  3.28095160e-01],\n",
       "        [ 2.61191501e-01,  6.18540600e-01,  5.37470573e-01,\n",
       "          5.41987462e-01,  6.38294261e-01],\n",
       "        [ 5.26178524e-01,  8.66117022e-01,  3.13991378e-03,\n",
       "          3.83075721e-01,  9.34856358e-01],\n",
       "        [-1.70370633e-05, -3.25384584e-04, -4.24785710e-04,\n",
       "         -1.57424473e-04, -2.63808520e-04],\n",
       "        [ 2.58765460e-01,  9.03620123e-01,  4.11099310e-01,\n",
       "          3.23599174e-01,  4.79919775e-01],\n",
       "        [ 1.22755846e-01,  4.51482104e-01,  2.42989394e-01,\n",
       "          9.33442668e-01,  3.37831130e-01],\n",
       "        [ 3.86164935e-01,  4.35133612e-01,  4.31833882e-01,\n",
       "          8.68077943e-01,  9.19821503e-01],\n",
       "        [ 2.06240558e-01,  3.37793125e-01,  7.00063714e-01,\n",
       "          2.14738599e-02,  9.93272048e-01],\n",
       "        [ 1.48287645e-01,  9.65635208e-01,  6.12012315e-01,\n",
       "          1.30482992e-01,  2.26073307e-01],\n",
       "        [-2.11197321e-04, -4.48742880e-04, -4.59930442e-04,\n",
       "         -6.37146459e-04, -2.49808854e-04],\n",
       "        [ 5.06937784e-01,  4.73721336e-01,  8.52891597e-01,\n",
       "          2.31478051e-01,  8.61736590e-01],\n",
       "        [ 6.02962270e-01,  2.90907313e-01,  4.20014396e-01,\n",
       "          4.64364075e-01,  7.12947594e-01],\n",
       "        [ 9.38176990e-01,  3.33463600e-01,  1.54068016e-01,\n",
       "          6.47003386e-01,  1.58949949e-01],\n",
       "        [ 4.37892269e-01,  3.66978135e-02,  6.42569896e-04,\n",
       "          1.65729109e-01,  3.60725383e-01],\n",
       "        [ 1.65972419e-01,  1.00913559e-01,  2.85070497e-01,\n",
       "          9.12894620e-01,  9.33269684e-01],\n",
       "        [ 5.93871213e-01,  2.64951636e-01,  8.43356907e-01,\n",
       "          6.81290821e-02,  8.42728995e-01],\n",
       "        [ 2.58733424e-01,  2.53394734e-01,  1.92434811e-01,\n",
       "          4.95520091e-01,  4.71752177e-01],\n",
       "        [ 6.45121702e-01,  1.12547908e-01,  8.87710470e-01,\n",
       "          5.77762792e-01,  6.15689914e-01],\n",
       "        [ 3.84621752e-01,  4.58894976e-01,  3.02828876e-01,\n",
       "          1.73106744e-01,  9.74292437e-03],\n",
       "        [ 3.54749424e-02,  1.08410981e-01,  9.57241761e-01,\n",
       "          6.83902225e-01,  9.01492288e-01],\n",
       "        [-2.91647964e-05, -5.57007681e-04, -7.27166912e-04,\n",
       "         -2.69486155e-04, -4.51599059e-04],\n",
       "        [ 3.08405659e-01,  1.60366474e-01,  1.01741540e-01,\n",
       "          5.07886748e-01,  7.84901323e-01],\n",
       "        [ 8.72770302e-01,  9.78461351e-01,  5.52841342e-01,\n",
       "          4.90559817e-01,  6.11706806e-01],\n",
       "        [ 6.71050971e-01,  3.82265961e-01,  1.42689091e-01,\n",
       "          2.87706099e-01,  3.93140957e-01],\n",
       "        [-7.87237863e-04, -2.38345045e-04, -4.68364298e-04,\n",
       "         -6.99342706e-04, -7.45602552e-05],\n",
       "        [-2.15078731e-04, -3.92768002e-04, -1.65570853e-04,\n",
       "         -4.46491694e-04, -4.60791554e-04],\n",
       "        [ 1.55855329e-01,  3.52574824e-01,  8.35346373e-01,\n",
       "          9.32961809e-01,  6.80984888e-01],\n",
       "        [ 8.78690472e-01,  5.40107221e-01,  5.30728137e-01,\n",
       "          6.61290319e-01,  9.12524096e-02],\n",
       "        [ 6.43380186e-01,  1.73529323e-01,  9.75272756e-01,\n",
       "          7.08882650e-01,  6.49587956e-01],\n",
       "        [-2.62982217e-05, -5.02260028e-04, -6.55694503e-04,\n",
       "         -2.42998667e-04, -4.07211901e-04]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Un test\n",
    "alpha=10**(-3)\n",
    "Min = np.array([rd.random() for i in range(50*5)]).reshape((50,5))\n",
    "Mout = np.array([rd.random() for i in range(50*5)]).reshape((50,5))\n",
    "wout = 12\n",
    "Nwin= np.array([1,8,27,4])\n",
    "negative = 4\n",
    "hog_loop(Min,Mout,alpha,wout,Nwin,negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in Pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMQ Dupre : \n",
    "\n",
    "regarder \n",
    "// ++i i++\n",
    "   for(auto it: temp)\n",
    "       *it = 0;\n",
    "    \n",
    "for(float* it = temp; it != ; ++it)\n",
    "      *it = 0;\n",
    "      \n",
    "RMQ : peut-être pas la peine de passer random en entier à chaque loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "\n",
    "#include <time.h>\n",
    "#include <stdlib.h>\n",
    "#include <stdio.h>\n",
    "#include <curand.h>\n",
    "#include <math.h>\n",
    "\n",
    "\n",
    "\n",
    "__device__ void loop(float *Min, float *Mout, float alpha, int *Nwin, int wout, int V, int d, int N, int negative, int* random, int idx){\n",
    "    \n",
    "    /*\n",
    "    HOGWILD LOOP\n",
    "    \n",
    "    float *Min : initialisé en dehors de pycuda, poids de la PREMIERE couche du RN (attention float * et non float **) (V*d)\n",
    "    float *Mout : initialisé en dehors de pycuda, poids de la DEUXIEME couche du RN (attention float * et non float **) (V*d)\n",
    "    float alpha : learning rate\n",
    "    int *Nwin : N input du contexte de l'output\n",
    "    int wout : output\n",
    "    int V : taille du vocabulaire (nombre de mots différents)\n",
    "    int d : taille de l'espace de représentation\n",
    "    int N : taille du contexte utilisé pour l'apprentissage (de chaque coté donc 2*N en tout)\n",
    "    int negative : nb de negative utilisé pour l'apprentissage\n",
    "    int* random : entiers aléat générés en dehors (difficulté pour générer de l'aléat sur le device) pour les negative\n",
    "    int idx : indice de la parallélization (utile ?)\n",
    "    \n",
    "    Une boucle de l'Algo 1 de l'article. Permet de mettre à jour Min et Mout pour un wout (et son contexte associé).\n",
    "    */\n",
    "\n",
    "    /* Init variables */\n",
    "    float* temp;\n",
    "    temp = (float *)malloc(sizeof(float)*d);\n",
    "    int label;\n",
    "    int target_word;\n",
    "    float inn;\n",
    "    float err;\n",
    "    \n",
    "    /* Boucle principale sur les 2*N inputs*/\n",
    "    for(int i=0;i<2*N;i++){\n",
    "        int input_word = Nwin[i];\n",
    "        for(int j=0;j<d;j++){\n",
    "            temp[j]=0;\n",
    "        }\n",
    "        for(int k=0; k<negative+1;k++){\n",
    "            if (k==0){\n",
    "                target_word = wout;\n",
    "                label = 1;\n",
    "            } else {\n",
    "                /* negative sampling */\n",
    "                target_word = random[idx*negative+k-1];\n",
    "                label = 0;\n",
    "            }\n",
    "            inn = 0;\n",
    "            for(int j=0;j<d;j++){\n",
    "                inn = inn + Min[input_word*d+j]*Mout[target_word*d+j];\n",
    "            }\n",
    "            err = label-(1/(1+exp(-inn)));\n",
    "            for(int j=0;j<d;j++){\n",
    "                temp[j] = temp[j]+err*Mout[target_word*d+j];\n",
    "            }\n",
    "            for(int j=0;j<d;j++){\n",
    "                Mout[target_word*d+j] = Mout[target_word*d+j]+alpha*err*Min[input_word*d+j];\n",
    "            }  \n",
    "        }\n",
    "        for(int j=0;j<d;j++){\n",
    "            Min[input_word*d+j] = Min[input_word*d+j]+alpha*temp[j]; \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void parallel(int *X, float *Min, float* Mout, int* random, int* cst_int, float* cst_float) {\n",
    "\n",
    "    /*\n",
    "    Parallélisation\n",
    "    int *X : la matrice du hot encoding\n",
    "    float *Min : Min initialisé\n",
    "    float *Mout : Mout initialisé\n",
    "    int* random : entiers aléatoires générés hors du device\n",
    "    int* cst_int : les constantes entières utiles (V,d,negative,N)\n",
    "    float* cst_float : les constantes float utiles (alpha)\n",
    "    */\n",
    "\n",
    "    /*préparation des paramètres pour la fonction loop*/\n",
    "    \n",
    "    \n",
    "    /*constantes entières passés depuis le code python*/\n",
    "    int V = cst_int[0];\n",
    "    int d = cst_int[1];\n",
    "    int negative = cst_int[2];\n",
    "    int N = cst_int[3];\n",
    "\n",
    "    /*constante float passé depuis python*/\n",
    "    float alpha = cst_float[0];\n",
    "    \n",
    "    /*l'index correspond au thread et indique simplement le wout sur lequel on travaille*/\n",
    "    int index = threadIdx.x%(V-2*N)+N; /*+N pour éviter les effets de bord*/\n",
    "    int wout = index;\n",
    "    \n",
    "    /*Calcul des mots du contexte de wout*/\n",
    "    int *Nwin;\n",
    "    Nwin = (int *)malloc(sizeof(int)*N*2);\n",
    "    for(int i=0;i<N;i++){\n",
    "        Nwin[i]= X[index+(i-N)];\n",
    "    }\n",
    "    for(int i=0;i<N;i++){\n",
    "        Nwin[i+N]= X[index+1+i];\n",
    "    }\n",
    "\n",
    "    loop(Min,Mout,alpha,Nwin,wout,V,d,N,negative,random,index);\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation des différentes variables\n",
    "d = 10\n",
    "V = np.shape(X_hot)[1]\n",
    "negative = 5\n",
    "N = 2\n",
    "alpha = 0.001\n",
    "\n",
    "cst_int = np.array([V,d,negative,N])\n",
    "cst_float = np.array([alpha])\n",
    "\n",
    "Min = np.random.rand(V,d)\n",
    "Mout = np.random.rand(V,d)\n",
    "\n",
    "random_neg = np.random.randint(V, size=(V,negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Min = Min.astype(np.float32)\n",
    "Min_orig = copy.deepcopy(Min)\n",
    "Mout = Mout.astype(np.float32)\n",
    "Mout_orig = copy.deepcopy(Mout)\n",
    "random_neg = random_neg.astype(np.int32)\n",
    "X = X.astype(np.int32)\n",
    "cst_int = cst_int.astype(np.int32)\n",
    "cst_float = cst_float.astype(np.float32)\n",
    "\n",
    "Min_gpu = cuda.mem_alloc(Min.nbytes)\n",
    "Mout_gpu = cuda.mem_alloc(Mout.nbytes)\n",
    "random_neg_gpu = cuda.mem_alloc(random_neg.nbytes)\n",
    "X_gpu = cuda.mem_alloc(X.nbytes)\n",
    "cst_int_gpu = cuda.mem_alloc(cst_int.nbytes)\n",
    "cst_float_gpu = cuda.mem_alloc(cst_float.nbytes)\n",
    "\n",
    "cuda.memcpy_htod(Min_gpu, Min)\n",
    "cuda.memcpy_htod(Mout_gpu, Mout)\n",
    "cuda.memcpy_htod(random_neg_gpu, random_neg)\n",
    "cuda.memcpy_htod(X_gpu,X)\n",
    "cuda.memcpy_htod(cst_int_gpu,cst_int)\n",
    "cuda.memcpy_htod(cst_float_gpu,cst_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"parallel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=time.time()\n",
    "func(X_gpu,Min_gpu,Mout_gpu,random_neg_gpu,cst_int_gpu,cst_float_gpu,block=(512,512,1))\n",
    "dt=time.time()-t0\n",
    "print(\"temps d'exécution\",dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_dtoh(Min,Min_gpu)\n",
    "cuda.memcpy_dtoh(Mout,Mout_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(Min!=Min_orig))\n",
    "print(np.sum(Mout!=Mout_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"10    : 0.00421\"\"\"\n",
    "\"\"\"100   : 0.00507\"\"\"\n",
    "\"\"\"1000  : 0.00400\"\"\"\n",
    "\"\"\"see https://stackoverflow.com/questions/9985912/how-do-i-choose-grid-and-block-dimensions-for-cuda-kernels\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
